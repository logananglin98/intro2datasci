<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="ch10-tweet-twet" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Tweet, Tweet!</title>

    <section xml:id="intro-to-x">
    <title>Introduction to X</title>
  <introduction>
	<figure xml:id="ch10-twitter-bird">
		<image source="twitter-bird.png" decorative = 'yes' width = '50%'/>
		
	</figure>
        <p>
					We’ve come a long way already: Basic skills in controlling R, some exposure to R-studio, knowledge of how to manage add-on packages, experience creating a function, essential descriptive statistics, and a start on sampling distributions and inferential statistics. In this chapter, we use the social media service Twitter to grab some up-to-the minute data and begin manipulating it.
				</p>
  </introduction>

				<p>
					Prior to this chapter we only worked with toy data sets: some made up data about a fictional family and the census head counts for the 50 states plus the District of Columbia. At this point we have practiced a sufficient range of skills to work with some real data. There are data sets everywhere, thousands of them, many free for the taking, covering a range of interesting topics from psychology experiments to film actors. For sheer immediacy, though, you can’t beat the Twitter social media service. As you may know from direct experience, Twitter is a micro-blogging service that allows people all over the world to broadcast brief thoughts (280 characters or less) that can then be read by their "followers" (other Twitter users who signed up to receive the sender’s messages). The developers of Twitter, in a stroke of genius, decided to make these postings, called tweets, available to the general public through a web page on the Twitter.com site, and additional through what is known as an application programming interface or API.
				</p>

				<p>
					Here’s where the natural extensibility of R comes in. An individual named Jeff Gentry who, at this writing, seems to be a data professional in the financial services industry, created an add-on package for R called  twitteR(not sure how it is pronounced, but "twit-are" seems pretty close). The twitteR package provides an extremely simple interface for downloading a list of tweets directly from the Twitter service into R. Using the interface functions in twitteR, it is possible to search through Twitter to obtain a list of tweets on a specific topic. Every tweet contains the text of the posting that the author wrote as well as lots of other useful information such as the time of day when a tweet was posted. Put it all together and it makes a fun way of getting up-to-the-minute data on what people are thinking about a wide variety of topics.
				</p>

				<p>
					The other great thing about working with twitteR is that we will use many, if not all of the skills that we have developed earlier in the book to put the interface to use.
				</p>

	</section>

		<section xml:id="a-token-of-your-esteem-using-oauth">
			<title>A Token of Your Esteem: Using OAuth </title>

			<p>
				Before we move forward with creating some code in Rstudio, there’s an important set of steps we need to accomplish at the Twitter website.
			</p>

			<p>
				In 2013, Twitter completed a transition to a new version of their application programming interface, or API. This new API requires the use of a technique for authorization, a way of proving to Twitter that you are who you are when you search for (or post) tweets from a software application. The folks at Twitter adopted an industry standard for this process known as OAuth. <idx>OAuth</idx><term>OAuth</term> provides a method for obtaining two pieces of information: a "secret" and a "key" without which it will be difficult if not downright impossible to work with Twitter (as well as twitteR). Here are the steps:
			</p>

			<p><ol>
				<li>
							
											<p>
								Get a Twitter account at Twitter.com if you don’t already have one.
							</p>
							
				</li>

				<li>
							
											<p>
								Go to the development page at Twitter (<url href="https://dev.twitter.com">https://dev.twitter.com</url>) and sign in with your Twitter credentials.
							</p>
							
				</li>

				<li>
							
											<p>
								Click on "Apps." The location of this may vary over time, but look for it near your profile picture on the top right corner of the screen.
							</p>
							
				</li>

				<li>
							
											<p>
								Apply for a permission to have a Developer account. You will need to link your phone number to your account. The purpose for the account will be Educational or Student. Then when prompted only indicate that we will be processing tweets outside of Twitter environment and press no for all others options such as “Using Tweet, Retweet and etc.” Congratulations, now you have a Twitter developer account.
							</p>
							
				</li>

				<li>
							
											<p>
								Click on "Create a New Application." Fill in the blanks with some sensible answers. Where it asks for a “website” you can give your own home page. This is a required response, so you will have to have some kind of web page to point to. In contrast, the “Callback URL” can be left blank. Click submit.
							</p>
							
				</li>

				<li>
							
											<p>
								Check the checkbox specified to allow your application should be set so that it can be used to sign in with Twitter.
							</p>
							<figure xml:id="ch10-twitter-enabling">
								<image source="twitter-enabling.png" width = '100%'>
								<shortdescription>
									<p>
										checkbox to "allow this aplication to be used to sign in with twitter" checked yes.
									</p>
								</shortdescription>
								<description>
									<p>
										this image shows a checkbox marked yes with the sentence "allow this aplication to be used to sign in with twitter" next to it. below the checkbox it says "When enabled you application can be used to 'Sign in with Twitter'."
									</p>
								</description>
								</image>
							</figure>

							
				</li>

				<li>
							
											<p>
								You will get a screen containing a whole bunch of data. Make sure to save it all, but the part that you will really need is the "Consumer key" and the "Consumer Secret," both of which are long strings of letters and numbers. These strings will be used later to get your application running in R. The reason these are such long strings of gibberish is that they are encrypted.
							</p>
							
				</li>

				<li>
							
											<p>
								Also take note of the Request Token URL and the Authorize URL. For the most part these are exactly the same across all uses of Twitter, but they may change over time, so you should make sure to stash them away for later. You do not need to click on the “Create my Access Token” button.
							</p>
							
				</li>

				<li>
							
											<p>
								Go to the Settings tab and make sure that "Read, Write and Access direct messages" is set.
							</p>
							
				</li>

			</ol></p>

			<p>
				You may notice on the Home-&gt;My applications screen in the <url href="http://dev.twitter.com">https://dev.twitter.com</url> interface that there are additional tabs along the top for different activities and tasks related to OAuth. There is a tab called Apps - details where you can always come back to get your Consumer key and Consumer secret information. Later in the chapter we will come back to the usage of your Consumer key and your Consumer secret but before we get there we have to get the twitteR package ready to go.
			</p>

		</section>

		<section xml:id="working-with-x">
			<title>Working with X</title>

			<p>
				Open the X assignment. R-studio will respond by showing a clean console screen and most importantly an R "workspace" that does not contain any of the old variables and data that we created in previous chapters. In order to use twitteR, we need to load several packages that it depends upon. These are called, in order "bitops", "RCurl", "RJSONIO", and once these are all in place "twitteR" itself. Rather than doing all of this by hand with the menus, let’s create some functions that will assist us and make the activity more repeatable. First, here is a function that takes as input the name of a package. It tests whether the package has been downloaded "installed" from the R code repository. If it has not yet been downloaded/installed, the function takes care of this. Then we use a new function, called require(), to prepare the package for further use. Let’s call our function "EnsurePackage" because it ensures that a package is ready for us to use. If you don’t recall this step from the previous chapter, you should click the "File" menu and then click "New" to create a new file of R script. Then, type or copy/paste the following code:
			</p>

			<p>
				EnsurePackage&lt;-function(x)
			</p>

			<p>
				{
			</p>

			<p>
				x &lt;- as.character(x)
			</p>

			<p>
				if (!require(x,character.only=TRUE))
			</p>

			<p>
				{
			</p>

			<p>
				install.packages(pkgs=x,
			</p>

			<p>
				repos="http://cran.r-project.org")
			</p>

			<p>
				require(x,character.only=TRUE)
			</p>

			<p>
				}
			</p>

			<p>
				}
			</p>

			<p>
				On Windows machines, the folder where new R packages are stored has to be configured to allow R to put new files there (“write” permissions). In Windows Explorer, you can right click on the folder and choose “Properties-&gt;Security” then choose your username and user group, click Edit, enable all permissions, and click OK. If you run into trouble, check out the Windows FAQ at CRAN by searching or using this web address: <url href="http://cran.r-project.org/bin/windows/base/rw-FAQ.html">R for Windows FAQ</url>.
			</p>

			<p>
				The <idx><c>require()</c></idx><term>require()</term> function on the fourth line above does the same thing as library(), which we learned in the previous chapter, but it also returns the value "FALSE" if the package you requested in the argument "x" has not yet been downloaded. 
			</p>

			<p>
				That same line of code also contains another new feature, the <idx>if statement</idx><term>"if" statement</term>. This is what computer scientists call a conditional. It tests the stuff inside the parentheses to see if it evaluates to TRUE or FALSE. If TRUE, the program continues to run the script in between the curly braces (lines 4 and 8). If FALSE, all the stuff in the curly braces is skipped. Also in the third line, in case you are curious, the arguments to the require() function include "x," which is the name of the package that was passed into the function, and "character.only=TRUE" which tells the require() function to expect x to be a character string. Last thing to notice about this third line: there is a "!" character that reverses the results of the logical test. Technically, it is the Boolean function NOT. It requires a bit of mental gyration that when require() returns FALSE, the "!" inverts it to TRUE, and that is when the code in the curly braces runs.
			</p>

			<p>
				Once you have this code in a script window, make sure to select the whole function and click Run in the toolbar to make R aware of the function. There is also a checkbox on that same toolbar called, "Source on Save," that will keep us from having to click on the Run button all the time. If you click the checkmark, then every time you save the source code file, Rstudio will rerun the code. If you get in the habit of saving after every code change you will always be running the latest version of your function.
			</p>

			<p>
				Now we are ready to put EnsurePackage() to work on the packages we need for twitteR. We’ll make a new function, "PrepareTwitter," that will load up all of our packages for us. Here’s the code:
			</p>

			<p>
				PrepareTwitter&lt;-function()
			</p>

			<p>
				{
			</p>

			<p>
				EnsurePackage("bitops")
			</p>

			<p>
				EnsurePackage("RCurl")
			</p>

			<p>
				EnsurePackage("RJSONIO")
			</p>

			<p>
				EnsurePackage("twitteR")
			</p>

			<p>
				EnsurePackage("ROAuth")
			</p>

			<p>
				}
			</p>

			<p>
				This code is quite straightforward: it calls the EnsurePackage() function we created before five times, once to load each of the packages we need. You may get some warning messages and these generally won’t cause any harm. If you are on Windows and you get errors about being able to write to your library remember to check the Windows FAQ as noted above.
			</p>

			<p>
				Make sure to save your script file once you have typed this new function in. You can give it any file name that makes sense to you, such as "twitterSupport." Now is also a good time to start the habit of commenting: <idx>comments</idx><term>Comments</term> are human readable messages that software developers leave for themselves and for others, so that everyone can remember what a piece of code is supposed to do. All computer languages have at least one "comment character" that sets off the human readable stuff from the rest of the code. In R, the comment character is #. For now, just put one comment line above each function you created, briefly describing it, like this:
			</p>

			<p>
				# EnsurePackage(x) Installs and loads a package
			</p>

			<p>
				# if necessary
			</p>

			<p>
				and this:
			</p>

			<p>
				# PrepareTwitter() Load packages for working
			</p>

			<p>
				# with twitteR
			</p>

			<p>
				Later on we will do a better job of commenting, but this gives us the bare minimum we need to keep going with this project. Before we move on, you should run the PrepareTwitter() function on the console command line to actually load the packages we need:
			</p>

			<p>
				&gt; <term>PrepareTwitter()</term>
			</p>

			<p>
				Note the parentheses after the function name, even though there is no argument to this function. What would happen if you left out the parentheses? Try it later to remind yourself of some basic R syntax rules.
			</p>

			<p>
				You may get a lot of output from running PrepareTwitter(), because your computer may need to download some or all of these packages. You may notice the warning message above, for example, about objects being "<idx>masked</idx><term>masked</term>." Generally speaking, this message refers to a variable or function that has become invisible because another variable or function with the same name has been loaded. Usually this is fine: the newer thing works the same as the older thing with the same name.
			</p>

			<p>
				Take a look at the four panes in R-Studio, each of which contains something of interest. The upper left pane is the code/ script window, where we should have the code for our two new functions. The lower left pane shows our R console with the results of the most recently run commands. The upper right pane contains our workspace and history of prior commands, with the tab currently set to workspace. As a reminder, in R parlance, workspace represents all of the currently available data objects and functions. Our two new functions which we have defined should be listed there, indicating that they have each run at least once and R is now aware of them. In the lower right pane, we have files, plots, packages, and help, with the tab currently set to packages.
			</p>

			<p>
				This window is scrolled to the bottom to show that RCurl, RJSONIO, and twitteR are all loaded and "libraryed" meaning that they are ready to use from the command line or from functions.
			</p>

			<p>
				<term>Getting New SSL Tokens on Windows</term>
			</p>

			<p>
				For Windows users, depending upon which version of operating system software you are using as well as your upgrade history, it may be necessary to provide new <idx>SSL certificates</idx><term>SSL certificates</term>. Certificates help to maintain secure communications across the Internet, and most computers keep an up-to-date copy on file, but not all of them do. If you encounter any problems using R to access the Internet, you may need new tokens.
			</p>

			<p>
				download.file(url="http://curl.haxx.se/ca/cacert.pem",+
			</p>

			<p>
				destfile="cacert.pem")
			</p>

			<p>
				This statement needs to be run before the R tries to contact Twitter for authentication. This is because twitteR uses RCurl which in turn employs SSL security whenever “https” appears in a URL. The command above downloads new certificates and saves them within the current working directory for R. You may need to use cacert.pem for many or most of the function calls to twitteR by adding the argument cainfo="cacert.pem".
			</p>

			<p>
				<term>Using Your OAuth Tokens</term>
			</p>

			<p>
				Remember at the beginning of the chapter that we went through some rigamarole to get a Consumer key and a Consumer secret from Twitter. Before we can get started in retrieving data from Twitter we need to put those long strings of numbers and letters to use.
			</p>

			<p>
				Begin this process by getting a credential from ROAuth. Remember that in the command below where I have put "lettersAndNumbers" you have to substitute in your ConsumerKey and your ConsumerSecret that you got from Twitter. The ConsumerKey is a string of upper and lowercase letters and digits about 22 characters long. The ConsumerSecret is also letters and digits and it is about twice as long as the ConsumerKey. Make sure to keep these private, especially the ConsumerSecret, and don’t share them with others. Here’s the command:
			</p>

			<p>
				&gt; credential &lt;OAuthFactory$new(consumerKey="lettersAndNumbers", +cons
			</p>

			<p>
				umerSecret="lettersAndNumbers", +requestURL="https://api.twitter.com/oauth/request_token", +accessURL="https://api.twitter.com/oauth/access_token", +authURL="https://api.twitter.com/oauth/authorize")
			</p>

			<p>
				This looks messy but is really very simple. If you now type:
			</p>

			<p>
				&gt; credential
			</p>

			<p>
				You will find that the credential data object is just a conglomeration of the various fields that you specified in the arguments to the OAuthFactory$new method. We have to put that data structure to work now with the following function call:
			</p>

			<p>
				&gt; credential$handshake()
			</p>

			<p>
				Or, if you have downloaded new certificates:
			</p>

			<p>
				&gt; credential$handshake(cainfo="cacert.pem")
			</p>

			<p>
				You will get a response back that looks like this:
			</p>

			<p>
				When complete, record the PIN given to you and provide it here:
			</p>

			<p>
				<em>To enable the connection, please direct your web browser to:</em>
			</p>

			<p>
				<em><url href="https://api.twitter.com/oauth/authorize?oauth_token=">https://api.twitter.com/oauth/authorize?oauth_token=</url>...</em>
			</p>

			<p>
				<em>When complete, record the PIN given to you and provide it here:</em>
			</p>

			<p>
				This will be followed by a long string of numbers. Weirdly, you have to go to a web browser and type in exactly what you see in the R-Studio output window (the URL and the long string of numbers). While typing the URL to be redirected to twitter, be sure that you type http:// instead of https:// otherwise Twitter will not entertain the request because the Twitter server invokes SSL security itself. If you type the URL correctly, Twitter will respond in your browser window with a big button that says "Authorize App." Go ahead and click on that and you will receive a new screen with a PIN on it (my PIN had seven digits). Take those seven digits and type them into the R-Studio console window (the credential$handshake() function will be waiting for them). Type the digits in front of “When complete, record the PIN given to you and provide it here:” Hit Enter and, assuming you get no errors, you are fully authorized! Hooray! What a crazy process! Thankfully, you should not have to do any of this again as long as you save the credential data object and restore it into future sessions. The credential object, and all of the other active data, will be stored in the default workspace when you exit R-Studio.
			</p>

			<p>
				<term>Ready, Set, Go!</term>
			</p>

			<p>
				Now let’s get some data from Twitter. First, tell the twitteR package that you want to use your shiny new credentials:
			</p>

			<p>
				&gt; registerTwitterOAuth(credential)
			</p>

			<p>
				[1] TRUE
			</p>

			<p>
				The return value of TRUE shows that the credential is working and ready to help you get data from Twitter. Subsequent commands using the twitteR package will pass through the authorized application interface.
			</p>

			<p>
				The twitteR package provides a function called searchTwitter() that allows us to retrieve some recent tweets based on a search term. Twitter users have invented a scheme for organizing their tweets based on subject matter. This system is called "<idx>hashtags</idx><term>hashtags</term>" and is based on the use of the hashmark character (#) followed by a brief text tag. For example, fans of Oprah Winfrey use the tag #oprah to identify their tweets about her. We will use the searchTwitter() function to search for hashtags about global climate change. The website hashtags.org lists a variety of hashtags covering a range of contemporary topics. You can pick any hashtag you like, as long as there are a reasonable number of tweets that can be retrieved. The searchTwitter() function also requires specifying the maximum number of tweets that the call will return. For now we will use 500, although you may find that your request does not return that many. Here’s the command:
			</p>

			<p>
				tweetList &lt;searchTwitter("#climate", n=500)
			</p>

			<p>
				As above, if you are on Windows, and you had to get new certificates, you may have to use this command:
			</p>

			<p>
				tweetList &lt;searchTwitter("#climate", n=500, cainfo="cacert.pem")
			</p>

			<p>
				Depending upon the speed of your Internet connection and the amount of traffic on Twitter’s servers, this command may take a short while for R to process. Now we have a new data object, tweetList, that presumably contains the tweets we requested. But what is this data object? Let’s use our R diagnostics to explore what we have gotten:
			</p>

			<p>
				&gt; mode(tweetList)
			</p>

			<p>
				[1] "list"
			</p>

			<p>
				Hmm, this is a type of object that we have not encountered before. In R, a <idx>list</idx><term>list</term> is an object that contains other data objects, and those objects may be a variety of different modes/types. Contrast this definition with a vector: A vector is also a kind of list, but with the requirement that all of the elements in the vector must be in the same mode/type. Actually, if you dig deeply into the definitions of R data objects, you may realize that we have already encountered one type of list: the dataframe. Remember that the dataframe is a list of vectors, where each vector is exactly the same length. So a dataframe is a particular kind of list, but in general lists do not have those two restrictions that dataframes have (i.e., that each element is a vector and that each vector is the same length).
			</p>

			<p>
				So we know that tweetList is a list, but what does that list contain? Let’s try using the str() function to uncover the structure of the list:
			</p>

			<p>
				&gt; str(tweetList)
			</p>

			<p>
				The output will scroll right off the screen, but a quick glance would show that it is pretty repetitive, with each 20 line block being quite similar. So let’s use the <idx><c>head()</c></idx><term>head()</term> function to just examine the first element of the list. The head() function allows you to just look at the first few elements of a data object. In this case we will look just at the first list element of the tweetList list. The command is:
			</p>

			<p>
				str(head(tweetList,1) 
			</p>
			<p> 
				This output is also long, but not quite as long.
			</p>

			<figure xml:id="ch10-str-head-tweetList">
				<image source="str-head-tweetList.png" width = '100%'>
					<shortdescription>
						<p>
							The image displays a console output showing the structure of a single tweet object. It details various fields within the tweet, such as text, favorited status, creation date, and screen name, along with associated methods.
						</p>
					</shortdescription>
					<description>
						<p>
								The image is a screenshot of a console window, likely an R console, displaying the output of the command str(head(tweetlist,1)). This command is used to show the structure of the first element from a list named tweetlist, which appears to contain tweet data. The output indicates that the element is a "Reference class 'status' [package 'twitterR']" object, possessing 10 fields. These fields are text, favorited, replyToSN, created, truncated, replyToSID, id, replyToUID, statusSource, and screenName.
								Below the fields, a list of 33 methods is shown, with 22 of them highlighted as "possibly relevant." These methods include common operations such as getCreated, getFavorited, getId, getText, getScreenName, and toDataFrame, suggesting functions to access or manipulate the tweet object's data. 
						</p>
					</description>
				</image>
			</figure>

			<p>
				The output looks pretty messy, but is simpler than it may first appear. Following the line "List of 1," there is a line that begins "$ :Reference class" and then the word ‘status’ in single quotes. In Twitter terminology a "<idx>status</idx><term>status</term>" is a single tweet posting (it supposedly tells us the "status" of the person who posted it). So the author of the R twitteR package has created a new kind of data object, called a ‘status’ that itself contains 10 fields. The fields are then listed out. For each line that begins with "..$" there is a field name and then a mode or data type and then a taste of the data that that field contains.
			</p>

			<p>
				So, for example, the first field, called "text" is of type "chr" (which means character/text data) and the field contains the string that starts with, "Get the real facts on gas prices." You can look through the other fields and see if you can make sense of them. There are two other data types in there: "<idx>logi</idx><term>logi</term>" stands for logical and that is the same as TRUE/FALSE; "<idx>POSIXct</idx><term>POSIXct</term>" is a format for storing the calendar date and time. (If you’re curious, POSIX is an old unix style operating system, where the current date and time were stored as the number of seconds elapsed since 12 midnight on January 1, 1970.) You can see in the "created" field that this particular tweet was created on April 5, 2012 one second after 2:10 PM. It does not show what time zone, but a little detective work shows that all Twitter postings are coded with "coordinated universal time" or what is usually abbreviated with UTC.
			</p>

			<p>
				One last thing to peek at in this data structure is about seven lines from the end, where it says, "and 33 methods..." In computer science lingo a "<idx>method</idx><term>method</term>" is an operation/activity/procedure that works on a particular data object. The idea of a method is at the heart of so-called "object oriented programming." One way to think of it is that the data object is the noun, and the methods are all of the verbs that work with that noun. For example you can see the method "getCreated" in the list: If you use the method getCreated() on a reference object of class ‘status’, the method will return the creation time of the tweet.
			</p>

			<p>
				If you try running the command:
			</p>

			<p>
				str(head(tweetList,2))
			</p>

			<p>
				you will find that the second item in the tweetList list is structured exactly like the first time, with the only difference being the specific contents of the fields. You can also run:
			</p>

			<p>
				length(tweetList)
			</p>

			<p>
				to find out how many items are in your list. The list obtained for this exercise was a full 500 items long. Se we have 500 complex items in our list, but every item had exactly the same structure, with 10 fields in it and a bunch of other stuff too. That raises a thought: tweetList could be thought of as a 500 row structure with 10 columns! That means that we could treat it as a dataframe if we wanted to (and we do, because this makes handling these data much more convenient as you found in the "Rows and Columns" chapter).
			</p>

			<p>
				Happily, we can get some help from R in converting this list into a dataframe. Here we will introduce four powerful new R functions: <idx><c>as()</c></idx><term>as()</term>, <idx><c>lapply()</c></idx><term>lapply()</term>, <idx><c>rbind()</c></idx><term>rbind()</term>, and <idx><c>do.call()</c></idx><term>do.call()</term>. The first of these, as(), performs a type coercion: in other words it changes one type to another type. The second of these, lapply(), applies a function onto all of the elements of a list. In the command below, lapply(tweetList, as.data.frame), applies the as.data.frame() coercion to each element in tweetList. Next, the rbind() function "binds" together the elements that are supplied to it into a row-by-row structure. Finally, the do.call() function executes a function call, but unlike just running the function from the console, allows for a variable number of arguments to be supplied to the function. The whole command we will use looks like this:
			</p>

			<p>
				tweetDF &lt;- do.call("rbind", lapply(tweetList, +
			</p>

			<p>
				as.data.frame))
			</p>

			<p>
				You might wonder a few things about this command. One thing that looks weird is "rbind" in double quotes. This is the required method of supplying the name of the function to do.call(). You might also wonder why we needed do.call() at all. Couldn’t we have just called rbind() directly from the command line? You can try it if you want, and you will find that it does provide a result, but not the one you want. The difference is in how the arguments to rbind() are supplied to it: if you call it directly, lapply() is evaluated first, and it forms a single list that is then supplied to rbind(). In contrast, by using do.call(), all 500 of the results of lapply() are supplied to rbind() as individual arguments, and this allows rbind() to create the nice rectangular dataset that we will need. The advantage of do.call() is that it will set up a function call with a variable number of arguments in cases where we don’t know how many arguments will be supplied at the time when we write the code.
			</p>

			<p>
				If you run the command above, you should see in the upper right hand pane of R-studio a new entry in the workspace under the heading of "Data." For the example we are running here, the entry says, "500 obs. of 10 variables." This is just what we wanted, a nice rectangular data set, ready to analyze. Later on, we may need more than one of these data sets, so let’s create a function to accomplish the commands we just ran:
			</p>

			<p>
				# TweetFrame() Return a dataframe based on a # search of Twitter
			</p>

			<p>
				TweetFrame&lt;-function(searchTerm, maxTweets)
			</p>

			<p>
				{
			</p>

			<p>
				twtList&lt;searchTwitter(searchTerm,n=maxTweets)
			</p>

			<p>
				return(do.call("rbind",+
			</p>

			<p>
				lapply(twtList,as.data.frame)))
			</p>

			<p>
				}
			</p>

			<p>
				There are three good things about putting this code in a function. First, because we put a comment at the top of the function, we will remember in the future what this code does. Second, if you test this function you will find out that the variable twtList that is created in the code above does not stick around after the function is finished running. This is the result of what computer scientists call "<idx>variable scoping</idx><term>variable scoping</term>." The variable twtList only exists while the TweetFrame() function is running. Once the function is done, twtList evaporates as if it never existed. This helps us to keep our workspace clean and avoid collecting lots of intermediate variables that are not reused.
			</p>

			<p>
				The last and best thing about this function is that we no longer have to remember the details of the method for using do.call(), rbind(), lapply(), and as.data.frame() because we will not have to retype these commands again: we can just call the function whenever we need it. And we can always go back and look at the code later. In fact, this would be a good reason to put in a comment just above the return() function. Something like this:
			</p>

			<p>
				# as.data.frame() coerces each list element into a row # lapply() applies this to all of the elements in twtList # rbind() takes all of the rows and puts them together # do.call() gives rbind() all the rows as individual elements
			</p>

			<p>
				Now, whenever we want to create a new data set of tweets, we can just call TweetFrame from the R console command line like this:
			</p>

			<p>
				lgData &lt;- TweetFrame("#ladygaga", 250)
			</p>

			<p>
				This command would give us a new dataframe "lgData" all ready to analyze, based on the supplied search term and maximum number of tweets.
			</p>

			<p>
				Let’s start to play with the tweetDF dataset that we created before. First, as a matter of convenience, let’s learn the attach() function. The <idx><c>attach()</c></idx><term>attach()</term> function saves us some typing by giving one particular dataframe priority over any others that have the same variable names. Normally, if we wanted to access the variables in our dataframe, we would have to use the $ notation, like this:
			</p>

			<p>
				tweetDF$created
			</p>

			<p>
				But if we run attach(tweetDF) first, we can then refer to created directly, without having to type the tweetDF$ before it:
			</p>

			<p>
				&gt; attach(tweetDF)
			</p>

			<p>
				&gt; head(created,4)
			</p>

			<p>
				[1] "2012-04-05 14:10:01 UTC" "2012-04-05 14:09:21 UTC"
			</p>

			<p>
				[3] "2012-04-05 14:08:15 UTC" "2012-04-05 14:07:12 UTC"
			</p>

			<p>
				Let’s visualize the creation time of the 500 tweets in our dataset. When working with time codes, the <idx><c>hist()</c></idx><term>hist()</term> function requires us to specify the approximate number of categories we want to see in the histogram:
			</p>

			<p>
				hist(created, breaks=15, freq=TRUE)
			</p>

			<p>
				This command yields the histogram that appears below. If we look along the x-axis (the horizontal), this string of tweets starts at about 4:20 AM and goes until about 10:10 AM, a span of roughly six hours. There are 22 different bars so each bar represents about 16 minutes for casual purposes we’ll call it a quarter of an hour. It looks like there are something like 20 tweets per bar, so we are looking at roughly 80 tweets per hour with the hashtag "#climate". This is obviously a pretty popular topic. This distribution does not really have a discernible shape, although it seems like there might be a bit of a growth trend as time goes on, particularly starting at about 7:40 AM. 

			</p>
			<figure xml:id="ch10-histogram-created">
				<image source="histogram-created.png" width = '100%'>
					<shortdescription>
						<p>
							this is a histogram showing the number of tweets made with the hashtag climate between 4:20am and 10:10am.
						</p>
					</shortdescription>
					<description>
						<p>
							this image is a histogram of tweets containing te hashtag #climate over time from 4:20 AM to 10:10 AM. there are 22 bars representing roughly a quarter of an hour. the distrobution has no real shape, but may show some growth towards the end.
						</p> 
					</description>
					</image>
			</figure>

			<p>
				<image source='media/image51.png'/>
			</p>

			<p>
				Take note of something very important about these data: It doesn’t make much sense to work with a measure of central tendency. Remember a couple of chapters ago when we were looking at the number of people who resided in different U.S. states? In that case it made sense to say that if State A had one million people and State B had three million people, then the average of these two states was two million people. When you’re working with timestamps, it doesn’t make a whole lot of sense to say that one tweet arrived at 7 AM and another arrived at 9 AM so the average is 8 AM. Fortunately, there’s a whole area of statistics concerned with "arrival" times and similar phenomena, dating back to a famous study by Ladislaus von Bortkiewicz of horsemen who died after being kicked by their horses. von Bortkiewicz studied each of 14 cavalry corps over a period of 20 years, noting when horsemen died each year. The distribution of the "arrival" of kickdeaths turns out to have many similarities to other arrival time data, such as the arrival of buses or subway cars at a station, the arrival of customers at a cash register, or the occurrence of telephone calls at a particular exchange. All of these kinds of events fit what is known as a "<idx>Poisson distribution</idx><term>Poisson distribution</term>" (named after Simeon Denis Poisson, who published it about half a century before von Bortkiewicz found a use for it). Let’s find out if the arrival times of tweets comprise a Poisson distribution.
			</p>

			<p>
				Right now we have the actual times when the tweets were posted, coded as a POSIX date and time variable. Another way to think about these data is to think of each new tweet as arriving a certain amount of time after the previous tweet. To figure that out, we’re going to have to "look back" a row in order to subtract the creation time of the previous tweet from the creation time of the current tweet. In order to be able to make this calculation, we have to make sure that our data are sorted in ascending order of arrival in other words the earliest one first and the latest one last. To accomplish this, we will use the order() function together with R’s built-in square bracket notation.
			</p>

			<p>
				As mentioned briefly in the previous chapter, in R, square brackets allow "indexing" into a list, vector, or data frame. For example, myList[3] would give us the third element of myList. Keeping in mind that a dataframe is a rectangular structure, really a two dimensional structure, we can address any element of a dataframe with both a row and column designator: myFrame[4,1] would give the fourth row and the first column. A shorthand for taking the whole column of a dataframe is to leave the row index empty: myFrame[ , 6] would give every row in the sixth column. Likewise, a shorthand for taking a whole row of a dataframe is to leave the column index empty: myFrame[10, ] would give every column in the tenth row. We can also supply a list of rows instead of just one row, like this: myFrame[ c(1,3,5), ] would return rows 1, 3, 5 (including the data for all columns, because we left the column index blank). We can use this feature to reorder the rows, using the order() function. We tell order() which variable we want to sort on, and it will give back a list of row indices in the order we requested. Putting it all together yields this command:
			</p>

			<p>
				tweetDF[order(as.integer(created)), ]
			</p>

			<p>
				Working our way from the inside to the outside of the expression above, we want to sort in the order that the tweets were created. We first coerce the variable "created" to integer it will then truly be expressed in the number of seconds since 1970 just in case there are operating system differences in how POSIX dates are sorted. We wrap this inside the order() function. The <idx><c>order()</c></idx><term>order()</term> function will provide a list of row indices that reflects the time ordering we want. We use the square brackets notation to address the rows in tweetDF, taking all of the columns by leaving the index after the comma empty.
			</p>

			<p>
				We have a choice of what to do with the dataframe that is returned from this command. We could assign it back to tweetDF, which would overwrite our original dataframe with the sorted version. Or we could create a new sorted dataframe and leave the original data alone, like so:
			</p>

			<p>
				sortweetDF &lt;- tweetDF[order(as.integer(created)), ]
			</p>

			<p>
				If you choose this method, make sure to detach() tweetDF and attach() sortweetDF so that later commands will work smoothly with the sorted dataframe:
			</p>

			<p>
				&gt; detach(tweetDF)
			</p>

			<p>
				&gt; attach(sortweetDF)
			</p>

			<p>
				Another option, which seems better than creating a new dataframe, would be to build the sorting into the TweetFrame() function that we developed at the beginning of the chapter. Let’s leave that to the chapter challenge. For now, we can keep working with sortweetDF.
			</p>

			<p>
				Technically, what we have with our created variable now is a time series, and because statisticians like to have convenient methods for dealing with time series, R has a built-in function, called <idx><c>diff()</c></idx><term>diff()</term>, that allows us to easily calculate the difference in seconds between each pair of neighboring values. Try it:
			</p>

			<p>
				<sub>&gt; diff(created)</sub>
			</p>

			<p>
				You should get a list of time differences, in seconds, between neighboring tweets. The list will show quite a wide range of intervals, perhaps as long as several minutes, but with many intervals near or at zero. You might notice that there are only 499 values and not 500: This is because you cannot calculate a time difference for the very first tweet, because we have no data on the prior tweet. Let’s visualize these data and see what we’ve got:
			</p>

			<p>

				&gt; hist(as.integer(diff(created)))

			</p>
			<figure xml:id="ch10-histogram-as-integer">
				<image source="histogram-as-integer.png" width = '100%'>
					<shortdescription>
						<p>
							this is a histogram showing the trend of time between 500 tweets.
						</p>
					</shortdescription>
					<description>
						<p>
							this histogram shows the difference in time between 500 tweets over time, and the data follows an exponential decrease showing that as more tweets are made the gap betweeen tem decreases.
						</p> 
					</description>
					</image>
			</figure>

			<p>
				As with earlier commands, we use <idx><c>as.integer()</c></idx><term>as.integer()</term> to coerce the time differences into plain numbers, otherwise hist() does not know how to handle the time differences. This histogram shows that the majority of tweets in this group come within 50 seconds or less of the previous tweets. A much smaller number of tweets arrive within somewhere between 50 and 100 seconds, and so on down the line. This is typical of a Poisson arrival time distribution. Unlike the raw arrival time data, we could calculate a mean on the time differences:
			</p>

			<p>
				&gt; mean(as.integer(diff(created)))
			</p>

			<p>
				[1] 41.12826
			</p>

			<p>
				We have to be careful though, in using measures of central tendency on this positively skewed distribution, that the value we get from the mean() is a sensible representation of central tendency. Remembering back to the previous chapter, and our discussion of the statistical mode (the most frequently occurring value), we learn that the mean and the mode are very different:
			</p>

			<p>
				&gt; library("modeest")
			</p>

			<p>
				&gt; mfv(as.integer(diff(created)))
			</p>

			<p>
				[1] 0
			</p>

			<p>
				We use the library() function to make sure that the add on package with the mfv() function is ready to use. The results of the <term>mfv()</term> function show that the most commonly occurring time interval between neighboring tweets is zero!
			</p>

			<p>
				Likewise the median shows that half of the tweets have arrival times of under half a minute:
			</p>

			<p>
				&gt; median(as.integer(diff(created)))
			</p>

			<p>
				[1] 28
			</p>

			<p>
				In the next chapter we will delve more deeply into what it means when a set of data are shaped like a Poisson distribution and what that implies about making use of the mean.
			</p>

			<p>
				One last way of looking at these data before we close this chapter. If we choose a time interval, such as 10 seconds, or 30 seconds, or 60 seconds, we can ask the question of how many of our tweet arrivals occurred within that time interval. Here’s code that counts the number of arrivals that occur within certain time intervals:
			</p>

			<p>
				&gt; sum((as.integer(diff(created)))&lt;60)
			</p>

			<p>
				[1] 375
			</p>

			<p>
				&gt; sum((as.integer(diff(created)))&lt;30)
			</p>

			<p>
				[1] 257
			</p>

			<p>
				&gt; sum((as.integer(diff(created)))&lt;10)
			</p>

			<p>
				[1] 145
			</p>

			<p>
				You could also think of these as ratios, for example 145/500 = 0.29.
			</p>

			<p>
				And where we have a ratio, we often can think about it as a probability: There is a 29% probability that the next tweet will arrive in 10 seconds or less. You could make a function to create a whole list of these probabilities. Some sample code for such a function appears at the end of the chapter. Some new scripting skills that we have not yet covered (for example, the "for loop") appear in this function, but try making sense out of it to stretch your brain. Output from this function created the plot that appears below. 

			</p>
			<figure xml:id="ch10-graph-plist">
				<image source="graph-plist.png" width = '100%'>
					<shortdescription>
						<p>
							explained in the following paragraph
						</p>
					</shortdescription>
					</image>
			</figure>

			<p>
				This is a classic Poisson distribution of arrival probabilities. The x-axis contains 10 second intervals (so by the time you see the number 5 on the x-axis, we are already up to 50 seconds). This is called a <idx>cumulative probability plot</idx><term>cumulative probability plot</term> and you read it by talking about the probability that the next tweet will arrive in the amount of time indicated on the x-axis or less. For example, the number five on the x-axis corresponds to about a 60% probability on the y-axis, so there is a 60% probability that the next tweet will arrive in 50 seconds or less. Remember that this estimate applies only to the data in this sample!
			</p>

			<p>
				In the next chapter we will reexamine sampling in the context of Poisson and learn how to compare two Poisson distributions to find out which hashtag is more popular.
			</p>

			<p>
				Let’s recap what we learned from this chapter. First, we have begun to use the project features of R-studio to establish a clean environment for each R project that we build. Second, we used the source code window of R-studio to build two or three very useful functions, ones that we will reuse in future chapters. Third, we practiced the skill of installing packages to extend the capabilities of R. Specifically, we loaded Jeff Gentry’s twitteR package and the other three packages it depends upon. Fourth, we put the twitteR package to work to obtain our own fresh data right from the web. Fifth, we started to condition that data, for example by creating a sorted list of tweet arrival times. And finally, we started to analyze and visualize those data, by conjecturing that this sample of arrival times fitted the classic Poisson distribution.
			</p>

			<p>
				<term>Chapter Challenge</term>
			</p>

			<p>
				Modify the TweetFrame() function created at the beginning of this chapter to sort the dataframe based on the creation time of the tweets. This will require taking the line of code from a few pages ago that has the order() function in it and adding this to the TweetFrame() function with a few minor modifications. Here’s a hint: Create a temporary dataframe inside the function and don’t attach it while you’re working with it. You’ll need to use the $ notation to access the variable you want to use to order the rows.
			</p>

    </section>
			<section xml:id="sources-6">
				<title>Sources</title>

				<p><ul>
					<li>
									
														<p>
										<url href="http://cran.r-project.org/web/packages/twitteR/twitteR.pdf">http://cran.r-project.org/web/packages/twitteR/twitteR.pdf</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://cran.r-project.org/web/packages/twitteR/vignettes/twitte">http://cran.r-project.org/web/packages/twitteR/vignettes/twitte R.pdf</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://en.wikipedia.org/wiki/Ladislaus_Bortkiewicz">http://en.wikipedia.org/wiki/Ladislaus_Bortkiewicz</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://en.wikipedia.org/wiki/Poisson_distribution">http://en.wikipedia.org/wiki/Poisson_distribution</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://hashtags.org/">http://hashtags.org/</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://www.inside-r.org/packages/cran/twitteR/docs/example">http://www.inside-r.org/packages/cran/twitteR/docs/example Oauth</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://www.khanacademy.org/math/probability/v/poisson-proc">http://www.khanacademy.org/math/probability/v/poisson-proc ess-1</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://www.khanacademy.org/math/probability/v/poisson-proc">http://www.khanacademy.org/math/probability/v/poisson-proc ess-2</url>
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="https://support.twitter.com/articles/49309">https://support.twitter.com/articles/49309</url> (hashtags explained)
									</p>
									
					</li>

					<li>
									
														<p>
										<url href="http://www.rdatamining.com/examples/text-mining">http://www.rdatamining.com/examples/text-mining</url>
									</p>
									
					</li>

				</ul></p>

			</section>

			<section xml:id="r-script-create-vector-of-probabilities-from-arrival-times">
				<title>R Script Create Vector of Probabilities From Arrival Times </title>

				<p>
					# ArrivalProbability Given a list of arrival times
				</p>

				<p>
					# calculates the delays between them using lagged differences
				</p>

				<p>
					# then computes a list of cumulative probabilities of arrival
				</p>

				<p>
					# for the sequential list of time increments
				</p>

				<p>
					# times A sorted, ascending list of arrival times in POSIXct
				</p>

				<p>
					# increment the time increment for each new slot, e.g. 10 sec
				</p>

				<p>
					# max the highest time increment, e.g., 240 sec
				</p>

				<p>
					#<sub># Returns an ordered list of probabilities in a numeric vector</sub>
				</p>

				<p>
					# suitable for plotting with plot()
				</p>

				<p>
					ArrivalProbability&lt;-function(times, increment, max)
				</p>

				<p>
					{
				</p>

				<p>
					# Initialize an empty vector
				</p>

				<p>
					plist &lt;NULL
				</p>

				<p>
					# Probability is defined over the size of this sample
				</p>

				<p>
					# of arrival times
				</p>

				<p>
					timeLen &lt;length(times)
				</p>

				<p>
					# May not be necessary, but checks for input mistake
				</p>

				<p>
					if (increment&gt;max) {return(NULL)}
				</p>

				<p>
					for (i in seq(increment, max, by=increment))
				</p>

				<p>
					{
				</p>

				<p>
					# diff() requires a sorted list of times
				</p>

				<p>
					# diff() calculates the delays between neighboring times
				</p>

				<p>
					# the logical test &lt;i provides a list of TRUEs and FALSEs
				</p>

				<p>
					# of length = timeLen, then sum() counts the TRUEs.
				</p>

				<p>
					# Divide by timeLen to calculate a proportion
				</p>

				<p>
					plist&lt;-c(plist,(sum(as.integer(diff(times))&lt;i))/timeLen)
				</p>

				<p>
					}
				</p>

				<p>
					return(plist)
				</p>

				<p>
					}
				</p>

				<p>
					<term><sub>R Functions Used in This Chapter</sub></term>
				</p>

				<p><ul>
					<li>
									
														<p>
										attach() Makes the variables of a dataset available without $
									</p>
									
					</li>

					<li>
									
														<p>
										as.integer() Coerces data into integers
									</p>
									
					</li>

					<li>
									
														<p>
										detach() Undoes an attach() function
									</p>
									
					</li>

					<li>
									
														<p>
										diff() Calculates differences between neighboring rows
									</p>
									
					</li>

					<li>
									
														<p>
										do.call() Calls a function with a variable number of arguments
									</p>
									
					</li>

					<li>
									
														<p>
										function() Defines a function for later use
									</p>
									
					</li>

					<li>
									
														<p>
										install.packages() Downloads and prepares a package for use
									</p>
									
					</li>

					<li>
									
														<p>
										lapply() Applies a function to a list
									</p>
									
					</li>

					<li>
									
														<p>
										library() Loads a package for use; like require()
									</p>
									
					</li>

					<li>
									
														<p>
										mean() Calculates the arithmetic mean of a vector
									</p>
									
					</li>

					<li>
									
														<p>
										hist() Plots a histogram from a list of data
									</p>
									
					</li>

					<li>
									
														<p>
										median() Finds the statistical center point of a list of numbers
									</p>
									
					</li>

					<li>
									
														<p>
										mfv() Most frequent value; part of the modeest() package
									</p>
									
					</li>

					<li>
									
														<p>
										mode() Shows the basic data type of an object
									</p>
									
					</li>

					<li>
									
														<p>
										order() Returns a sorted list of index numbers
									</p>
									
					</li>

					<li>
									
														<p>
										rbind() Binds rows into a dataframe object
									</p>
									
					</li>

					<li>
									
														<p>
										require() Tests if a package is loaded and loads it if needed
									</p>
									
					</li>

					<li>
									
														<p>
										searchTwitter() Part of the twitteR package
									</p>
									
					</li>

					<li>
									
														<p>
										str() Describes the structure of a data object
									</p>
									
					</li>

					<li>
									
														<p>
										sum() Adds up a list of numbers
									</p>
									
					</li>

				</ul></p>
                </section>

</chapter>