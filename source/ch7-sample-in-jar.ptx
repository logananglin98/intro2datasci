<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="ch-sample-in-jar" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Sample in a Jar</title>

<subsection xml:id="sample-in-a-jar">
  <title>Sample in a Jar</title>

  <introduction>


				<figure>
	<image source="jelly-belly.png" width="40%"/>
					<caption></caption>
</figure>

				<p>
					<idx>sampling distributions</idx>
					<term>sampling distributions</term> <em> are the conceptual key to statistical inference. Many approaches to understanding sampling distributions use examples of drawing marbles or gumballs from a large jar to illustrate the influences of randomness on sampling. Using the list of U.S. states illustrates how a non-normal distribution nonetheless has a normal sampling distribution of means.</em>
				</p>
  </introduction>
  
				<p>
					Imagine a gum ball jar full of gumballs of two different colors, red and blue. The jar was filled from a source that provided 100 red gum balls and 100 blue gum balls, but when these were poured into the jar they got all mixed up. If you drew eight gumballs from the jar at random, what colors would you get? If things worked out perfectly, which they never do, you would get four red and four blue. This is half and half, the same ratio of red and blue that is in the jar as a whole. Of course, it rarely works out this way, does it? Instead of getting four red and four blue you might get three red and five blue or any other mix you can think of. In fact, it would be possible, though perhaps not likely, to get eight red gumballs. The basic situation, though, is that we really don’t know what mix of red and blue we will get with one draw of eight gumballs. That’s uncertainty for you, the forces of randomness affecting our sample of eight gumballs in unpredictable ways.
				</p>

				<p>
					Here’s an interesting idea, though, that is no help at all in predicting what will happen in any one sample, but is great at showing what will occur <em>in the long run</em>. Pull eight gumballs from the jar, count the number of red ones and then throw them back. We do not have to count the number of blue because 8 = #red + #blue. Mix up the jar again and then draw eight more gumballs and count the number of red. Keep doing this many times. Here’s an example of what you might get:
				</p>

				<table>
					<title></title>
					<tabular>
					<row header="yes">
						<cell halign="left"><term>DRAW</term></cell>
						<cell halign="left"><term>#RED</term></cell>
					</row>
					<row class="odd">
						<cell halign="left">1</cell>
						<cell halign="left">5</cell>
					</row>
					<row class="even">
						<cell halign="left">2</cell>
						<cell halign="left">3</cell>
					</row>
					<row class="odd">
						<cell halign="left">3</cell>
						<cell halign="left">6</cell>
					</row>
					<row class="even">
						<cell halign="left">4</cell>
						<cell halign="left">2</cell>
					</row>
					</tabular>
				</table>

				<p>
					<term> </term>Notice that the left column is just counting up the number of sample draws we have done. The right column is the interesting one because it is the count of the number of red gumballs in each particular sample draw. In this example, things are all over the place. In sample draw 4 we only have two red gumballs, but in sample draw 3 we have 6 red gumballs. But the most interesting part of this example is that if you <em>average</em> the number of red gumballs over all of the draws, the average comes out to <em>exactly four red gumballs</em> per draw, which is what we would expect in a jar that is half and half. Now this is a contrived example and we won’t always get such a perfect result so quickly, but if you did four thousand draws instead of four, you would get pretty close to the perfect result.
				</p>

				<p>
					<idx>population</idx>
					<idx>sampling</idx>
					This process of repeatedly drawing a subset from a "<term>population</term>" is called "<term>Sampling</term>," and the end result of doing lots of sampling is a Sampling Distribution. Note that we are using the word population in the previous sentence in its statistical sense to refer to the totality of units from which a sample can be drawn. It is just a coincidence that our dataset contains the number of people in each state and that this value is also referred to as "population." Next we will get R to help us draw lots of samples from our U.S. state dataset.
				</p>

				<p>
					<idx>sample()</idx>
					Conveniently, R has a function called <term>sample()</term>, that will draw a random sample from a data set with just a single call. We can try it now with our state data:
				</p>

				<pre>
				&gt; sample(USstatePops$...1,size=16,replace=TRUE)
				
				[1] 4533372 19378102 897934 1052567 672591 18801310 2967297
				
				[8] 5029196  
				</pre>
				
				<p>
					As a matter of practice, note that we called the sample() function with three arguments. The first argument was the data source. For the second and third arguments, rather than rely on the order in which we specify the arguments, we have used "named arguments" to make sure that R does what we wanted. The size=16 argument asks R to draw a sample of 16 state data values. The replace=TRUE argument specifies a style of sampling which statisticians use very often to simplify the mathematics of their proofs. For us, sampling with or without replacement does not usually have any practical effects, so we will just go with what the statisticians typically do.
				</p>
				<p>
					When we’re working with numbers such as these state values, instead of counting gumball colors, we’re more interested in finding out the average, or what you now know as the mean. So we could also ask R to calculate a mean() of the sample for us:
				</p>
				<pre>
				&gt; mean(sample(USstatePops$...1,size=16, + replace=TRUE))
				
				[1] 8198359
				</pre>
				

				<p>
					There’s the nested function call again. The output no longer shows the 16 values that R has sampled from the list of 51. Instead it used those 16 values to calculate the mean and display that for us. If you have a good memory, or merely took the time to look in the last chapter, you will remember that the actual mean of our 51 observations is 6,053,834. So the mean that we got from this one sample of 16 states is really not even close to the true mean value of our 51 observations. Are we worried? Definitely not! We know that when we draw a sample, whether it is gumballs or states, we will never hit the true population mean right on the head. We’re interested not in any one sample, but in what happens over the long haul. So now we’ve got to get R to repeat this process for us, not once, not four times, but four hundred times or four thousand times. Like most programming languages, R has a variety of ways of repeating an activity. One of the easiest ones to use is the replicate() function. To start, let’s just try four replications:
				</p>
				<pre>
					&gt; replicate(4, mean(sample(USstatePops$...1,+ size=16,replace=TRUE)),simplify=TRUE)
				
					[1] 10300486 11909337 8536523 5798488	
				</pre>
				

				<p>
					Couldn’t be any easier. We took the exact same command as before, which was a nested function to calculate the mean() of a random sample of 16 states (shown above in bold). This time, we put that command inside the replicate() function so we could run it over and over again. The simplify=TRUE argument asks R to return the results as a simple vector of means, perfect for what we are trying to do. We only ran it four times, so that we would not have a big screen full of numbers. From here, though, it is easy to ramp up to repeating the process four hundred times. You can try that and see the output, but for here in the book we will encapsulate the whole replicate function inside another mean(), so that we can get the average of all 400 of the sample means. Here we go:
				</p>
				<pre>
				&gt; mean(replicate(400, mean( + sample(USstatePops$...1,size=16,replace=TRUE)),+ simplify=TRUE))
				
				[1] 5958336
				</pre>
				

				<p>
					In the command above, the outermost mean()command is bolded to show what is different from the previous command. So, put into
				</p>

				<p>
					that words, this deeply nested command accomplishes the following: a) Draw 400 samples of size n=8 from our full data set of 51 states; b)
				</p>

				<p>
					Calculate the mean from each sample and keep it in a list; c) When finished with the list of 400 of these means, calculate the mean of that list of means. You can see that the mean of four hundred sample means is 5,958,336. Now that is still not the exact value of the whole data set, but it is getting close. We’re off by about 95,000, which is roughly an error of about 1.6% (more precisely, 95,498/ 6,053,834 = 1.58%. You may have also noticed that it took a little while to run that command, even if you have a fast computer. There’s a lot of work going on there! Let’s push it a bit further and see if we can get closer to the true mean for all of our data:
				</p>
				<pre>
				&gt; mean(replicate(4000, mean( + sample(USstatePops$...1,size=16,replace=TRUE)),+ simplify=TRUE))
				
				[1] 6000972	
				</pre>
				

				<p>
					Now we are even closer! We are now less than 1% away from the true population mean value. Note that the results you get may be a bit different, because when you run the commands, each of the 400 or 4000 samples that is drawn will be slightly different than the ones that were drawn for the commands above. What will not be much different is the overall level of accuracy.
				</p>

				<p>
					We’re ready to take the next step. Instead of summarizing our whole sampling distribution in a single average, let’s look at the distribution of means using a histogram.
				</p>

				<p>
					The histogram displays the complete list of 4000 means as frequencies. Take a close look so that you can get more practice reading frequency histograms. This one shows a very typical configuration that is almost bell-shaped, but still has a bit of "skewness" off to the right.The tallest, and therefore most frequent range of values is right near the true mean of 6,053,834.
				</p>

				<figure>
	<image source="graph-replicate.png"/>
					<caption>Histogram of replicate(4000, mean(sample(USstatePops$V1, size = 16, replace = TRUE)), simplify = = TRUE) </caption>
</figure>

				<p>
					By the way, were you able to figure out the command to generate this histogram on your own? All you had to do was substitute hist() for the outermost mean() in the previous command. In case you struggled, here it is:
				</p>

				<pre>
					hist(replicate(4000, mean( + sample(USstatePops$...1,size=16,replace=TRUE)), + simplify=TRUE))
				</pre>

				<p>
					<idx>the law of large numbers</idx>
					<idx>central limit theorem</idx>
					This is a great moment to take a deep breath. We’ve just covered a couple hundred years of statistical thinking in just a few pages. In fact, there are two big ideas, "<term>the law of large numbers</term>" and the "<term>central limit theorem</term>" that we have just partially demonstrated. These two ideas literally took mathematicians like Gerolamo Cardano (1501-1576) and Jacob Bernoulli (1654-1705) several centuries to figure out. If you look these ideas up, you may find a lot of bewildering mathematical details, but for our purposes, there are two really important take-away messages. First, if you run a statistical process a large number of times, it will converge on a stable result. For us, we knew what the average population was of the 50 states plus the District of Columbia. These 51 observations were our population, and we wanted to know how many smaller subsets, or samples, of size n=16 we would have to draw before we could get a good approximation of that true value. We learned that drawing one sample provided a poor result. Drawing 400 samples gave us a mean that was off by 1.5%. Drawing 4000 samples gave us a mean that was off by less than 1%. If we had kept going to 40,000 or 400,000 repetitions of our sampling process, we would have come extremely close to the actual average of 6,053,384.
				</p>

				<p>
					Second, when we are looking at sample means, and we take the law of large numbers into account, we find that the distribution of sampling means starts to create a bell-shaped or normal distribution, and the center of that distribution, the mean of all of those sample means gets really close to the actual population mean. It gets closer faster for larger samples, and in contrast, for smaller samples you have to draw lots and lots of them to get really close. Just for fun, let's illustrate this with a sample size that is larger than 16. Here’s a run that only repeats 100 times, but each time draws a sample of n=51 (equal in size to the population):
				</p>

				<pre>
				&gt; mean(replicate(100, mean( + sample(USstatePops$...1,size=51,replace=TRUE)),+ simplify=TRUE))
				
				[1] 6114231
				</pre>

				<p>
					Now, we’re only off from the true value of the population mean by about one tenth of one percent. You might be scratching your head now, saying, "Wait a minute, isn’t a sample of 51 the same thing as the whole list of 51 observations?" This is confusing, but it goes back to the question of sampling with replacement that we examined a couple of pages ago (and that appears in the command above as replace=TRUE). Sampling with replacement means that as you draw out one value to include in your random sample, you immediately chuck it back into the list so that, potentially, it could get drawn again either immediately or later. As mentioned before, this practice simplifies the underlying proofs, and it does not cause any practical problems, other than head scratching. In fact, we could go even higher in our sample size with no trouble:
				</p>

				<pre>
				&gt; mean(replicate(100, mean( + sample(USstatePops$...1,size=120,replace=TRUE)), + simplify=TRUE))
				
				[1] 6054718
				</pre>

				<p>
					That command runs 100 replications using samples of size n=120. Look how close the mean of the sampling distribution is to the population mean now! Remember that this result will change a little bit every time you run the procedure, because different random samples are being drawn for each run. But the rule of thumb is that the bigger your sample size, what statisticians call n, the closer your estimate will be to the true value. Likewise, the more trials you run, the closer your population estimate will be.
				</p>

				<p>
					So, if you’ve had a chance to catch your breath, let’s move on to making use of the sampling distribution. First, let’s save one distribution of sample means so that we have a fixed set of numbers to work with:
				</p>

				<pre>
					SampleMeans &lt;- replicate(10000, mean(sample(USstatePops$...1,size=5,+ replace=TRUE)),simplify=TRUE)
				</pre>

				<p>
					The bolded part is new. We’re saving a distribution of sample means to a new vector called "SampleMeans". We should have 10,000 of them:
				</p>

				<pre>
				&gt; length(SampleMeans)

				[1] 10000
				</pre>

				<p>
					And the mean of all of these means should be pretty close to our population mean of 6,053,384:
				</p>

				<pre>
				&gt; mean(SampleMeans)
				
				[1] 6065380
				</pre>

				<p>
					You might also want to run a histogram on SampleMeans and see what the frequency distribution looks like. Right now, all we need to look at is a summary of the list of sample means:
				</p>

				<pre>
				&gt; summary(SampleMeans)
				
				Min. 1st Qu. Median Mean 3rd Qu. Max. 799100 3853000 5370000 6065000 7622000 25030000
				</pre>

				<p>
					If you need a refresher on the median and quartiles, take a look back at Chapter 3 Rows and Columns.
				</p>

				<p>
					This summary is full of useful information. First, take a look at the max and the min. The minimum sample mean in the list was 799,100. Think about that for a moment. How could a sample have a mean that small when we know that the true mean is much higher? Rhode Island must have been drawn several times in that sample! The answer comes from the randomness involved in sampling. If you run a process 10,000 times you are definitely going to end up with a few weird examples. Its almost like buying a lottery ticket. The vast majority of tickets are the usual not a winner. Once in a great while, though, there is a very unusual ticket a winner. Sampling is the same: The extreme events are unusual, but they do happen if you run the process enough times. The same goes for the maximum: at 25,030,000 the maximum sample mean is much higher than the true mean.
				</p>

				<p>
					At 5,370,000 the median is quite close to the mean, but not exactly the same because we still have a little bit of rightward skew (the "tail" on the high side is slightly longer than it should be because of the reverse J-shape of the original distribution). The median is very useful because it divides the sample exactly in half: 50%, or exactly 5000 of the sample means are larger than 5,370,000 and the other 50% are lower. So, if we were to draw one more sample from the population it would have a fifty-fifty chance of being above the median. The quartiles help us to cut things up even more finely. The third quartile divides up the bottom 75% from the top 25%. So only 25% of the sample means are higher than 7,622,000. That means if we drew a new sample from the population that there is only a 25% chance that it will be larger than that. Likewise, in the other direction, the first quartile tells us that there is only a 25% chance that a new sample would be less than 3,853,000.
				</p>

				<p>
					<idx>quantile()</idx>
					There is a slightly different way of getting the same information from R that will prove more flexible for us in the long run. The <term>quantile()</term> function can show us the same information as the median and the quartiles, like this:
				</p>

				<pre>
				&gt; quantile(SampleMeans, probs=c(0.25,0.50,0.75))
				
				25% 50% 75%
				
				3853167 5370314 7621871
				</pre>

				<p>
					You will notice that the values are just slightly different, by less than one tenth of one percent, than those produced by the summary() function. These are actually more precise, although the less precise ones from summary() are fine for most purposes. One reason to use quantile() is that it lets us control exactly where we make the cuts. To get quartiles, we cut at 25% (0.25 in the command just above), at 50%, and at 75%. But what if we wanted instead to cut at 2.5% and 97.5%? Easy to do with quantile():
				</p>
				<pre>
				&gt; quantile(SampleMeans, probs=c(0.025,0.975))
				
				2.5% 97.5%
				
				2014580 13537085
				</pre>

				<p>
					So this result shows that, if we drew a new sample, there is only a 2.5% chance that the mean would be lower than 2,014,580. Like
				</p>

				<p>
					wise, there is only a 2.5% chance that the new sample mean would be higher than 13,537,085 (because 97.5% of the means in the sampling distribution are lower than that value).
				</p>

				<p>
					Now let’s put this knowledge to work. Here is a sample of the number of people in a certain area, where each of these areas is some kind of a unit associated with the U.S.:
				</p>

				<p>
					3,706,690 159,358 106,405 55,519 53,883
				</p>

				<p>
					We can easily get these into R and calculate the sample mean:
				</p>

				<pre>
				&gt; MysterySample &lt;- c(3706690, 159358, 106405, + 55519, 53883)
				
				mean(MysterySample)
				
				[1] 816371
				</pre>

				<p>
					The mean of our mystery sample is 816,371. The question is, is this a sample of U.S. states or is it something else? Just on its own it would be hard to tell. The first observation in our sample has more people in it than Kansas, Utah, Nebraska, and several other states. We also know from looking at the distribution of raw population data from our previous example that there are many, many states that are quite small in the number of people. Thanks to the work we’ve done earlier in this chapter, however, we have an excellent basis for comparison. We have the sampling distribution of means, and it is fair to say that if we get a new mean to look at, and the new mean is way out in the extreme areas of the sample distribution, say, below the 2.5% mark or above the 97.5% mark, then it seems much less likely that our MysterySample is a sample of states.
				</p>

				<p>
					In this case, we can see quite clearly that 816,371 is on the extreme low end of the sampling distribution. Recall that when we ran the quantile() command we found that only 2.5% of the sample means in the distribution were smaller than 2,014,580.
				</p>

				<p>
					In fact, we could even play around with a more stringent criterion:
				</p>

				<pre>
				&gt; quantile(SampleMeans, probs=c(0.005,0.995))
				
				0.5% 99.5%
				
				1410883 16792211
				</pre>

				<p>
					This quantile() command shows that only 0.5% of all the sample means are lower than 1,410,883. So our MysterySample mean of 816,371 would definitely be a very rare event, if it were truly a sample of states. From this we can infer, tentatively but based on good statistical evidence, that our MysterySample is <em>not</em> a sample of states. The mean of MysterySample is just too small to be very likely to be a sample of states.
				</p>

				<p>
					And this is in fact correct: MysterySample contains the number of people in five different U.S. territories, including Puerto Rico in the Caribbean and Guam in the Pacific. These territories are land masses and groups of people associated with the U.S., but they are not states and they are different in many ways than states. For one thing they are all islands, so they are limited in land mass. Among the U.S. states, only Hawaii is an island, and it is actually bigger than 10 of the states in the continental U.S. The key thing to take away is that the mean of this sample was sufficiently different from a known distribution of means that we could make an inference that the sample <em>was not drawn from the original population of data</em>.
				</p>

				<p>
					This reasoning is the basis for virtually all statistical inference. You construct a comparison distribution, you mark off a zone of extreme values, and you compare any new sample of data you get to the distribution to see if it falls in the extreme zone. If it does, you tentatively conclude that the new sample was obtained from some other source than what you used to create the comparison distribution.
				</p>

				<p>
					If you feel a bit confused, take heart. There’s 400-500 years of mathematical developments represented in that one preceding paragraph. Also, before we had cool programs like R that could be used to create and analyze actual sample distributions, most of the material above was taught as a set of formulas and proofs. Yuck! Later in the book we will come back to specific statistical procedures that use the reasoning described above. For now, we just need to take note of three additional pieces of information.
				</p>

				<p>
					First, we looked at the mean of the sampling distribution with mean() and we looked at its shaped with hist(), but we never quantified the spread of the distribution:
				</p>

				<pre>
				&gt; sd(SampleMeans)
				
				[1] 3037318
				</pre>

				<p>
					<idx>standard error of the mean</idx>
					This shows us the standard deviation of the distribution of sampling means. Statisticians call this the "<term>standard error of the mean</term>." This chewy phrase would have been clearer, although longer, if it had been something like this: "the standard deviation of the distribution of sample means for samples drawn from a population." Unfortunately, statisticians are not known for giving things clear labels. Suffice to say that when we are looking at a distribution and each data point in that distribution is itself a representation of a sample (for example, a mean), then the standard deviation is referred to as the standard error.
				</p>

				<p>
					Second, there is a shortcut to finding out the standard error that does not require actually constructing an empirical distribution of 10,000 (or any other number) of sampling means. It turns out that the standard deviation of the original raw data and the standard error are closely related by a simple bit of algebra:
				</p>

				<pre>
				&gt; sd(USstatePops$...1)/sqrt(5)
				
				[1] 3051779
				</pre>

				<p>
					The formula in this command takes the standard deviation of the original state data and divides it by the square root of the sample size. Remember three of four pages ago when we created the SampleMeans vector by using the replicate() and sample() commands, and that we used a sample size of n=5. That’s what you see in the formula above, inside of the sqrt() function. In R, and other software sqrt() is the abbreviation for "square root" and not for "squirt" as you might expect. So if you have a set of observations and you calculate their standard deviation, you can also calculate the standard error for a distribution of means (each of which has the same sample size), just by dividing by the square root of the sample size. You may notice that the number we got with the shortcut was slightly larger than the number that came from the distribution itself, but the difference is not meaningful (and only arises because of randomness in the distribution). Another thing you may have noticed is that the larger the sample size, the smaller the standard error. This leads to an important rule for working with samples: the bigger the better.
				</p>

				<p>
					The last thing is another shortcut. We found out the 97.5% cut point by constructing the sampling distribution and then using quantile to tell us the actual cuts. You can also cut points just using the mean and the standard error. Two standard errors down from the mean is the 2.5% cut point and two standard errors up from the mean is the 97.5% cut point.
				</p>

				<pre>
				&gt; StdError&lt;-sd(USstatePops$...1)/sqrt(5)
				
				&gt; CutPoint975&lt;-mean(USstatePops$...1)+(2 * StdError)
				
				&gt; CutPoint975
				
				[1] 12157391
				</pre>

				<p>
					You will notice again that this value is different from what we calculated with the quantile() function using the empirical distribution. The differences arise because of the randomness in the distribution that we constructed. The value above is an estimate that is based on statistical proofs, whereas the empirical SampleMeans list that we constructed is just one of a nearly infinite range of such lists that we could create. We could easily reduce the discrepancy between the two methods by using a larger sample size and by having more replications included in the sampling distribution.
				</p>

				<p>
					To summarize, with a data set that includes 51 data points with the numbers of people in states, and a bit of work using R to construct a distribution of sampling means, we have learned the following:
				</p>

				<p><ul>
					<li>
									<blockquote>
														<p>
										Run a statistical process a large number of times and you get a consistent pattern of results.
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										Taking the means of a large number of samples and plotting them on a histogram shows that the sample means are fairly well normally distributed and that the center of the distribution is very, very close to the mean of the original raw data.
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										This resulting distribution of sample means can be used as a basis for comparisons. By making cut points at the extreme low and high ends of the distribution, for example 2.5% and 97.5%, we have a way of comparing any new information we get.
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										If we get a new sample mean, and we find that it is in the extreme zone defined by our cut points, we can tentatively conclude that the sample that made that mean is a different kind of thing than the samples that made the sampling distribution.
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										A shortcut and more accurate way of figuring the cut points involves calculating the "standard error" based on the standard deviation of the original raw data.
									</p>
									</blockquote>
					</li>

				</ul></p>

				<p>
					We’re not statisticians at this point, but the process of reasoning based on sampling distributions is at the heart of inferential statistics, so if you have followed the logic presented in this chapter, you have made excellent progress towards being a competent user of applied statistics.
				</p>

			</subsection>

			<subsection xml:id="chapter-challenge-3">
				<title>Chapter Challenge </title>

				<p>
					Collect a sample consisting of at least 20 data points and construct a sampling distribution. Calculate the standard error and use this
				</p>

				<p>
					to calculate the 2.5% and 97.5% distribution cut points. The data points you collect should represent instances of the same phenomenon. For instance, you could collect the prices of 20 textbooks, or count the number of words in each of 20 paragraphs.
				</p>

			</subsection>

			<subsection xml:id="sources-4">
				<title>Sources </title>

				<p><ul>
					<li>
									<blockquote>
														<p>
										<url href="http://en.wikipedia.org/wiki/Central_limit_theorem">http://en.wikipedia.org/wiki/Central_limit_theorem</url>
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										<url href="http://en.wikipedia.org/wiki/Gerolamo_Cardano">http://en.wikipedia.org/wiki/Gerolamo_Cardano</url>
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										<url href="http://en.wikipedia.org/wiki/Jacob_Bernoulli">http://en.wikipedia.org/wiki/Jacob_Bernoulli</url>
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										<url href="http://en.wikipedia.org/wiki/Law_of_large_numbers">http://en.wikipedia.org/wiki/Law_of_large_numbers</url>
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										<url href="http://en.wikipedia.org/wiki/List_of_U.S._states_and_territories">http://en.wikipedia.org/wiki/List_of_U.S._states_and_territories _by_population</url>
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										<url href="http://www.khanacademy.org/math/statistics/v/central-limit-th">http://www.khanacademy.org/math/statistics/v/central-limit-th eorem</url>
									</p>
									</blockquote>
					</li>

				</ul></p>

			</subsection>

			<subsection xml:id="r-commands-used-in-this-chapter">
				<title>R Commands Used in This Chapter </title>

				<p><ul>
					<li>
									<blockquote>
														<p>
										length() The number of elements in a vector
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										mean() The arithmetic mean or average of a set of values
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										quantile() Calculates cut points based on percents/proportions
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										sample() Chooses elements at random from a vector
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										sd() Calculates standard deviation
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										replicate() Runs an expression/calculation many times
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										sqrt() Calculates square root
									</p>
									</blockquote>
					</li>

					<li>
									<blockquote>
														<p>
										summary() Summarizes contents of a vector
									</p>
									</blockquote>
					</li>

				</ul></p>
        </subsection>

</chapter>